# Machine Learning Engineer Learning Path - Responsible AI for Devs: Privacy & Safety

ğŸ“˜ <a href='https://fern-stop-81f.notion.site/Machine-Learning-Engineer-Learning-Path-Responsible-AI-for-Devs-Privacy-Safety-1d513f9f5c038034baf6e90a16130d4d?pvs=4'> Read Here </a> 

## ğŸ—’ï¸ Summary
This learning module explores the critical aspects of AI privacy and safety, beginning with the fundamental need for privacy in AI systems and progressing through key de-identification and randomized techniques that help protect sensitive data. It delves into advanced approaches like Differential Privacy with DP-SGD and Federated Learning, which enable secure, decentralized model training. The module also covers system-level security within Google Cloud and Generative AI environments. It concludes with AI safety evaluation methods and training strategies focused on responsible AI behavior, including instruction fine-tuning and Reinforcement Learning with Human Feedback (RLHF) to ensure models act safely and ethically.

## ğŸ“š Table of Contents
1. AI Privacy
2. What is the need of Privacy
3. De-Identification Techniques
4. Randomised Techniques
5. DP-SGD
6. Federated Learning
7. System Security on Google Cloud & Gen AI
8. AI Safety Evaluation
9. Model Training for Safety - Instruction Fine-Tuning
10. Model Training for Safety - RLHF
